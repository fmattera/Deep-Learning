{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogoqHDOxbXVu",
        "outputId": "6822230f-75ee-4d52-f6e2-6d9be9dae93a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.8/dist-packages (1.16.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.8/dist-packages (from streamlit) (2.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from streamlit) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (4.4.0)\n",
            "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.8/dist-packages (from streamlit) (21.3)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (1.5)\n",
            "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.8/dist-packages (from streamlit) (1.0.1)\n",
            "Requirement already satisfied: validators>=0.2 in /usr/local/lib/python3.8/dist-packages (from streamlit) (0.20.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.8/dist-packages (from streamlit) (3.1.30)\n",
            "Requirement already satisfied: semver in /usr/local/lib/python3.8/dist-packages (from streamlit) (2.13.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.8/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (5.2.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.4 in /usr/local/lib/python3.8/dist-packages (from streamlit) (2.25.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.8/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.8/dist-packages (from streamlit) (3.19.6)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (6.0.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (4.2.0)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.8/dist-packages (from streamlit) (0.8.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (13.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit) (0.12.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit) (4.3.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from gitpython!=3.1.19->streamlit) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=1.4->streamlit) (3.11.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=14.1->streamlit) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.21.0->streamlit) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil->streamlit) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit) (2.10)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich>=10.11.0->streamlit) (2.6.1)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from rich>=10.11.0->streamlit) (0.9.1)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from validators>=0.2->streamlit) (4.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (5.10.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (22.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.8/dist-packages (0.11.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.8/dist-packages (0.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.8/dist-packages (0.2.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from diffusers) (7.1.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from diffusers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from diffusers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from diffusers) (3.9.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from diffusers) (6.0.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from diffusers) (0.11.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from diffusers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.10.0->diffusers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->diffusers) (3.11.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.8/dist-packages (5.2.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyngrok) (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (3.19.6)\n",
            "--2023-01-10 18:22:08--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5188 (5.1K) [text/plain]\n",
            "Saving to: ‘/usr/local/lib/python3.8/dist-packages/google/protobuf/internal/builder.py’\n",
            "\n",
            "/usr/local/lib/pyth 100%[===================>]   5.07K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-10 18:22:09 (42.8 MB/s) - ‘/usr/local/lib/python3.8/dist-packages/google/protobuf/internal/builder.py’ saved [5188/5188]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.8/dist-packages (3.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!pip install diffusers transformers accelerate scipy safetensors\n",
        "!pip install -qq ftfy\n",
        "!pip install -qq \"ipywidgets>=7,<8\"\n",
        "!pip install pyngrok\n",
        "!pip install protobuf\n",
        "#%cd ..\n",
        "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /usr/local/lib/python3.8/dist-packages/google/protobuf/internal/builder.py\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile img2img.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import io\n",
        "import pandas as pd \n",
        "import os\n",
        "import torch\n",
        "import wget\n",
        "import shutil\n",
        "import inspect\n",
        "import warnings\n",
        "from typing import List, Optional, Union\n",
        "import requests\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from tqdm.auto import tqdm\n",
        "from copy import deepcopy\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "    \n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid\n",
        "\n",
        "\n",
        "\n",
        "def login_huggingface(key = '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'):\n",
        "    from huggingface_hub import login\n",
        "    login(key)\n",
        "\n",
        "def load_concepts(repo_id_embeds = \"sd-concepts-library/klippan-black-sofa\", pretrained_model_name_or_path = \"stabilityai/stable-diffusion-2\" ):\n",
        "  \n",
        "    embeds_url = \"\" #Add the URL or path to a learned_embeds.bin file in case you have one\n",
        "    placeholder_token_string = \"\" #Add what is the token string in case you are uploading your own embed\n",
        "\n",
        "    downloaded_embedding_folder = \"./downloaded_embedding\"\n",
        "    if not os.path.exists(downloaded_embedding_folder):\n",
        "        os.mkdir(downloaded_embedding_folder)\n",
        "    if(not embeds_url):\n",
        "        embeds_path = hf_hub_download(repo_id=repo_id_embeds, filename=\"learned_embeds.bin\")\n",
        "        token_path = hf_hub_download(repo_id=repo_id_embeds, filename=\"token_identifier.txt\")\n",
        "        \n",
        "        \n",
        "        #https://techbeamers.com/python-copy-file/#:~:text=The%20copy()%20method%20functions,source%20after%20copying%20its%20content. \n",
        "        shutil.copy(embeds_path, downloaded_embedding_folder)\n",
        "        #!cp $embeds_path $downloaded_embedding_folder\n",
        "\n",
        "        shutil.copy(token_path, downloaded_embedding_folder)\n",
        "        #!cp $token_path $downloaded_embedding_folder\n",
        "        with open(f'{downloaded_embedding_folder}/token_identifier.txt', 'r') as file:\n",
        "            placeholder_token_string = file.read()\n",
        "    else:\n",
        "        wget.download(embeds_url, f\"{downloaded_embedding_folder}/learned_embeds.bin\") #wget -q -O $downloaded_embedding_folder/learned_embeds.bin $embeds_url\n",
        "\n",
        "    learned_embeds_path = f\"{downloaded_embedding_folder}/learned_embeds.bin\"\n",
        "\n",
        "    tokenizer = CLIPTokenizer.from_pretrained(\n",
        "        pretrained_model_name_or_path,\n",
        "        subfolder=\"tokenizer\",\n",
        "    )\n",
        "    text_encoder = CLIPTextModel.from_pretrained(\n",
        "        pretrained_model_name_or_path, subfolder=\"text_encoder\", torch_dtype=torch.float16\n",
        "    )\n",
        "    load_learned_embed_in_clip(learned_embeds_path, text_encoder, tokenizer, )\n",
        "    return tokenizer, text_encoder\n",
        "\n",
        "\n",
        "def load_learned_embed_in_clip(learned_embeds_path, text_encoder, tokenizer, token=None):\n",
        "  loaded_learned_embeds = torch.load(learned_embeds_path, map_location=\"cpu\")\n",
        "  \n",
        "  # separate token and the embeds\n",
        "  trained_token = list(loaded_learned_embeds.keys())[0]\n",
        "  embeds = loaded_learned_embeds[trained_token]\n",
        "\n",
        "  # cast to dtype of text_encoder\n",
        "  dtype = text_encoder.get_input_embeddings().weight.dtype\n",
        "  embeds.to(dtype)\n",
        "\n",
        "  # add the token in tokenizer\n",
        "  token = token if token is not None else trained_token\n",
        "  num_added_tokens = tokenizer.add_tokens(token)\n",
        "  if num_added_tokens == 0:\n",
        "    raise ValueError(f\"The tokenizer already contains the token {token}. Please pass a different `token` that is not already in the tokenizer.\")\n",
        "  \n",
        "  # resize the token embeddings\n",
        "  text_encoder.resize_token_embeddings(len(tokenizer))\n",
        "  \n",
        "  # get the id for the token and assign the embeds\n",
        "  token_id = tokenizer.convert_tokens_to_ids(token)\n",
        "  text_encoder.get_input_embeddings().weight.data[token_id] = embeds\n",
        "\n",
        "\n",
        "\n",
        "#Make it only run once:\n",
        "#https://docs.streamlit.io/library/advanced-features/caching#example-1-basic-usage\n",
        "@st.cache(hash_funcs={StableDiffusionImg2ImgPipeline: lambda _: None}) #https://github.com/streamlit/streamlit/issues/3113\n",
        "def setup_model(pretrained_model_name_or_path = \"stabilityai/stable-diffusion-2\" , device = 'mps', concepts = [\"sd-concepts-library/center-table\", \"sd-concepts-library/klippan-black-sofa\"]):    \n",
        "    login_huggingface()\n",
        "    if type(concepts) == list:\n",
        "        for concept in concepts:\n",
        "            tokenizer, text_encoder = load_concepts(concept)\n",
        "    elif type(concepts) == str:\n",
        "        tokenizer, text_encoder = load_concepts(concepts)    \n",
        "    \n",
        "    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "        pretrained_model_name_or_path,\n",
        "        tokenizer = tokenizer,\n",
        "        text_encoder = text_encoder,\n",
        "        revision=\"fp16\", \n",
        "        torch_dtype=torch.float16,\n",
        "        use_auth_token=False,\n",
        "        feature_extractor=None,\n",
        "        safety_checker=None,\n",
        "    )\n",
        "    pipe = pipe.to(device)\n",
        "    print(\"Model set-up\")\n",
        "    return pipe\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.backends.mps.is_available(): device = 'mps'\n",
        "if torch.cuda.is_available(): device = 'cuda'\n",
        "print(device)\n",
        "pipe = deepcopy(setup_model(device = device))\n",
        "    \n",
        "\n",
        "header = st.container()\n",
        "app = st.container()\n",
        "with header:\n",
        "    st.title('Ultimate Designs')\n",
        "    st.write('An OpenAI powered tool that helps users generate interior designs effortlessly.') \n",
        "    st.write('Redesign your room in different styles, Easy and Free!') \n",
        "    st.write('Here are some examples:')\n",
        "\n",
        "    # col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    # show1 = Image.open('show1.png') \n",
        "    # show2 = Image.open('show2.png')\n",
        "    # show3 = Image.open('show3.png') \n",
        "    # show3 = show3.resize((512, 512))\n",
        "\n",
        "    # col1.image(show1)\n",
        "    # col2.image(show2)\n",
        "    # col3.image(show3)\n",
        "\n",
        "\n",
        "with app:\n",
        "\n",
        "    st.header('Reimagine Room')\n",
        "    st.write('Select your desired prompts and upload a picture of your room')\n",
        "    url = st.text_input(\"Please insert the url to your picture\")\n",
        "    st.write(\"example url:  https://media.istockphoto.com/id/521806786/photo/3d-rendering-of-empty-room-interior-white-brown-colors.jpg?b=1&s=170667a&w=0&k=20&c=dnsyx7qNFEU7susAMx_AnJl8wdIpY8qpuREbW8nk30A=\")\n",
        "    \n",
        "    prompt = st.text_input(\"Please type a prompt\")\n",
        "    st.write(\"example prompt: Photograph of a modern living room with a <klippan-black-sofa> black couch, national geographic, high resolution.\")\n",
        "    \n",
        "    neg_prompt = st.text_input(\"Negative prompt (optional)\")\n",
        " \n",
        "    print(\"WAITING\")\n",
        "    if st.button('DONE'):\n",
        "        print(\"DONE\")\n",
        "        response = requests.get(url)\n",
        "        init_img = Image.open(io.BytesIO(response.content)).convert(\"RGB\")\n",
        "        init_img = init_img.resize((512, 512))\n",
        "        st.write(prompt)\n",
        "        st.image(init_img)\n",
        "\n",
        "        all_images = [] \n",
        "        num_samples = 1 # {type:\"number\"}\n",
        "        num_rows = 2 # {type:\"number\"}\n",
        "        for row in range(num_rows):\n",
        "            if neg_prompt:\n",
        "                images = pipe(\n",
        "                    prompt=[prompt] * num_samples, \n",
        "                    negative_prompt=[neg_prompt] * num_samples,\n",
        "                    num_inference_steps = 45, \n",
        "                    init_image=init_img, \n",
        "                    strength=0.8, \n",
        "                    guidance_scale=12.5, \n",
        "                    ).images\n",
        "            else:\n",
        "                images = pipe(\n",
        "                    prompt=[prompt] * num_samples, \n",
        "                    num_inference_steps = 45, \n",
        "                    init_image=init_img, \n",
        "                    strength=0.8, \n",
        "                    guidance_scale=12.5, \n",
        "                    ).images\n",
        "            all_images.extend(images)\n",
        "\n",
        "        grid = image_grid(all_images, num_rows, num_samples)\n",
        "        st.image(grid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD-VrwtUbdpd",
        "outputId": "76664eb8-c1e2-48b4-db38-ecc6b569e8cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting img2img.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile txt2img.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import io\n",
        "import pandas as pd \n",
        "import os\n",
        "import torch\n",
        "import wget\n",
        "import shutil\n",
        "import inspect\n",
        "import warnings\n",
        "from typing import List, Optional, Union\n",
        "import requests\n",
        "\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "import torch\n",
        "from torch import autocast\n",
        "from tqdm.auto import tqdm\n",
        "from copy import deepcopy\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "    \n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid\n",
        "\n",
        "\n",
        "\n",
        "def login_huggingface(key = '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'):\n",
        "    from huggingface_hub import login\n",
        "    login(key)\n",
        "\n",
        "def load_concepts(repo_id_embeds = \"sd-concepts-library/klippan-black-sofa\", pretrained_model_name_or_path = \"stabilityai/stable-diffusion-2\" ):\n",
        "    embeds_url = \"\" #Add the URL or path to a learned_embeds.bin file in case you have one\n",
        "    placeholder_token_string = \"\" #Add what is the token string in case you are uploading your own embed\n",
        "\n",
        "    downloaded_embedding_folder = \"./downloaded_embedding\"\n",
        "    if not os.path.exists(downloaded_embedding_folder):\n",
        "        os.mkdir(downloaded_embedding_folder)\n",
        "    if(not embeds_url):\n",
        "        embeds_path = hf_hub_download(repo_id=repo_id_embeds, filename=\"learned_embeds.bin\")\n",
        "        token_path = hf_hub_download(repo_id=repo_id_embeds, filename=\"token_identifier.txt\")\n",
        "        \n",
        "        \n",
        "        #https://techbeamers.com/python-copy-file/#:~:text=The%20copy()%20method%20functions,source%20after%20copying%20its%20content. \n",
        "        shutil.copy(embeds_path, downloaded_embedding_folder)\n",
        "        #!cp $embeds_path $downloaded_embedding_folder\n",
        "\n",
        "        shutil.copy(token_path, downloaded_embedding_folder)\n",
        "        #!cp $token_path $downloaded_embedding_folder\n",
        "        with open(f'{downloaded_embedding_folder}/token_identifier.txt', 'r') as file:\n",
        "            placeholder_token_string = file.read()\n",
        "    else:\n",
        "        wget.download(embeds_url, f\"{downloaded_embedding_folder}/learned_embeds.bin\") #wget -q -O $downloaded_embedding_folder/learned_embeds.bin $embeds_url\n",
        "\n",
        "    learned_embeds_path = f\"{downloaded_embedding_folder}/learned_embeds.bin\"\n",
        "\n",
        "    tokenizer = CLIPTokenizer.from_pretrained(\n",
        "        pretrained_model_name_or_path,\n",
        "        subfolder=\"tokenizer\",\n",
        "    )\n",
        "    text_encoder = CLIPTextModel.from_pretrained(\n",
        "        pretrained_model_name_or_path, subfolder=\"text_encoder\", torch_dtype=torch.float16\n",
        "    )\n",
        "    load_learned_embed_in_clip(learned_embeds_path, text_encoder, tokenizer, )\n",
        "    return tokenizer, text_encoder\n",
        "\n",
        "\n",
        "def load_learned_embed_in_clip(learned_embeds_path, text_encoder, tokenizer, token=None):\n",
        "  loaded_learned_embeds = torch.load(learned_embeds_path, map_location=\"cpu\")\n",
        "  \n",
        "  # separate token and the embeds\n",
        "  trained_token = list(loaded_learned_embeds.keys())[0]\n",
        "  embeds = loaded_learned_embeds[trained_token]\n",
        "\n",
        "  # cast to dtype of text_encoder\n",
        "  dtype = text_encoder.get_input_embeddings().weight.dtype\n",
        "  embeds.to(dtype)\n",
        "\n",
        "  # add the token in tokenizer\n",
        "  token = token if token is not None else trained_token\n",
        "  num_added_tokens = tokenizer.add_tokens(token)\n",
        "  if num_added_tokens == 0:\n",
        "    raise ValueError(f\"The tokenizer already contains the token {token}. Please pass a different `token` that is not already in the tokenizer.\")\n",
        "  \n",
        "  # resize the token embeddings\n",
        "  text_encoder.resize_token_embeddings(len(tokenizer))\n",
        "  \n",
        "  # get the id for the token and assign the embeds\n",
        "  token_id = tokenizer.convert_tokens_to_ids(token)\n",
        "  text_encoder.get_input_embeddings().weight.data[token_id] = embeds\n",
        "\n",
        "\n",
        "\n",
        "#Make it only run once:\n",
        "#https://docs.streamlit.io/library/advanced-features/caching#example-1-basic-usage\n",
        "@st.cache(hash_funcs={StableDiffusionPipeline: lambda _: None}) #https://github.com/streamlit/streamlit/issues/3113\n",
        "def setup_model(pretrained_model_name_or_path = \"stabilityai/stable-diffusion-2\" , device = 'mps', concepts = [\"sd-concepts-library/center-table\", \"sd-concepts-library/klippan-black-sofa\"]):    \n",
        "    login_huggingface()\n",
        "    if type(concepts) == list:\n",
        "        for concept in concepts:\n",
        "            tokenizer, text_encoder = load_concepts(concept)\n",
        "    elif type(concepts) == str:\n",
        "        tokenizer, text_encoder = load_concepts(concepts)    \n",
        "    \n",
        "    scheduler = EulerDiscreteScheduler.from_pretrained(pretrained_model_name_or_path, subfolder=\"scheduler\")\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        pretrained_model_name_or_path, \n",
        "        scheduler=scheduler, \n",
        "        tokenizer = tokenizer, \n",
        "        text_encoder = text_encoder,  \n",
        "        torch_dtype=torch.float16)\n",
        "\n",
        "    pipe = pipe.to(device)\n",
        "    print(\"Model set-up\")\n",
        "    print(type(pipe))\n",
        "    return pipe\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.backends.mps.is_available(): device = 'mps'\n",
        "if torch.cuda.is_available(): device = 'cuda'\n",
        "print(device)\n",
        "pipe = deepcopy(setup_model(device = device))\n",
        "    \n",
        "\n",
        "header = st.container()\n",
        "app = st.container()\n",
        "with header:\n",
        "    st.title('Ultimate Designs')\n",
        "    st.write('An OpenAI powered tool that helps users generate interior designs effortlessly.') \n",
        "    st.write('Redesign your room in different styles, Easy and Free!') \n",
        "    st.write('Here are some examples:')\n",
        "\n",
        "    # col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    # show1 = Image.open('show1.png') \n",
        "    # show2 = Image.open('show2.png')\n",
        "    # show3 = Image.open('show3.png') \n",
        "    # show3 = show3.resize((512, 512))\n",
        "\n",
        "    # col1.image(show1)\n",
        "    # col2.image(show2)\n",
        "    # col3.image(show3)\n",
        "\n",
        "\n",
        "with app:\n",
        "\n",
        "    st.header('Reimagine Room')\n",
        "    st.write('Describe your dream room!')\n",
        "    prompt = st.text_input(\"Please type a prompt\")\n",
        "    st.write(\"example prompt: prompt = Equirectangular render of a modern living room with a <klippan-black-sofa> couch and a <wakefit-coffee-table> table, natural colors, ambient occlusion, 8k uhd.\")\n",
        "    \n",
        "    neg_prompt = st.text_input(\"Negative prompt (optional)\")\n",
        " \n",
        "    print(\"WAITING\")\n",
        "    if st.button('DONE'):\n",
        "        print(\"DONE\")\n",
        "        \n",
        "        st.write(prompt)\n",
        "        \n",
        "\n",
        "        all_images = [] \n",
        "        num_samples = 1 # {type:\"number\"}\n",
        "        num_rows = 2 # {type:\"number\"}\n",
        "        for row in range(num_rows):\n",
        "            if neg_prompt:\n",
        "                images = pipe(\n",
        "                    prompt=[prompt] * num_samples, \n",
        "                    negative_prompt=[neg_prompt] * num_samples,\n",
        "                    num_inference_steps = 45, \n",
        "                    guidance_scale=12.5, \n",
        "                    ).images\n",
        "            else:\n",
        "                images = pipe(\n",
        "                    prompt=[prompt] * num_samples, \n",
        "                    num_inference_steps = 45, \n",
        "                    guidance_scale=12.5, \n",
        "                    ).images\n",
        "            all_images.extend(images)\n",
        "\n",
        "        grid = image_grid(all_images, num_rows, num_samples)\n",
        "        st.image(grid)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k7XG2a21OSh",
        "outputId": "8281bd91-3d1d-4c24-a252-f5d3af15d610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting txt2img.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run img2img.py &>/dev/null&"
      ],
      "metadata": {
        "id": "_SMEETHGfZG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2Hx6V7hZgnGoPRahmawplhzQ5Xo_7DwFM28B7Ske6BiPjGvYK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfRv6YApbdru",
        "outputId": "6fd61d34-b94b-4103-b1fc-c115614738cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5c57Gj9bduG",
        "outputId": "d875f03a-f2f3-4115-93da-a7e3cc7c5af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-10 18:22:16--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.202.168.65, 18.205.222.128, 54.161.241.46, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.202.168.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  3.36MB/s    in 6.9s    \n",
            "\n",
            "2023-01-10 18:22:23 (1.90 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13832437/13832437]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_SCpm_uePEm",
        "outputId": "06816109-a94a-4807-c0a7-db9eacdd071d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw(\"./ngrok http 8501 &\")"
      ],
      "metadata": {
        "id": "a8VuRUDtePHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If this gives an error, run the cell above once more.\n"
      ],
      "metadata": {
        "id": "-8NrSYIi6834"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0MHMIxvedHF",
        "outputId": "3593f5b7-c8cc-4745-88c7-fb3e70f7ad02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://7ef5-35-204-35-50.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/img2img.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHT9DHenedI4",
        "outputId": "91774348-b20a-422b-e388-c35407294158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.204.35.50:8501\u001b[0m\n",
            "\u001b[0m\n",
            "cuda\n",
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid.\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "Login successful\n",
            "Downloading: 100% 511/511 [00:00<00:00, 423kB/s]\n",
            "Fetching 12 files:  17% 2/12 [00:00<00:01,  5.57it/s]\n",
            "Downloading: 100% 624/624 [00:00<00:00, 531kB/s]\n",
            "Fetching 12 files:  25% 3/12 [00:01<00:03,  2.48it/s]\n",
            "Downloading:   0% 0.00/681M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   1% 5.32M/681M [00:00<00:12, 53.2MB/s]\u001b[A\n",
            "Downloading:   2% 10.9M/681M [00:00<00:12, 55.0MB/s]\u001b[A\n",
            "Downloading:   2% 16.8M/681M [00:00<00:11, 56.6MB/s]\u001b[A\n",
            "Downloading:   3% 23.1M/681M [00:00<00:11, 59.1MB/s]\u001b[A\n",
            "Downloading:   4% 29.0M/681M [00:00<00:11, 59.2MB/s]\u001b[A\n",
            "Downloading:   5% 35.4M/681M [00:00<00:10, 60.7MB/s]\u001b[A\n",
            "Downloading:   6% 41.8M/681M [00:00<00:10, 61.9MB/s]\u001b[A\n",
            "Downloading:   7% 48.0M/681M [00:00<00:10, 61.2MB/s]\u001b[A\n",
            "Downloading:   8% 54.1M/681M [00:00<00:10, 59.7MB/s]\u001b[A\n",
            "Downloading:   9% 60.3M/681M [00:01<00:10, 60.4MB/s]\u001b[A\n",
            "Downloading:  10% 66.4M/681M [00:01<00:10, 59.9MB/s]\u001b[A\n",
            "Downloading:  11% 72.6M/681M [00:01<00:10, 60.5MB/s]\u001b[A\n",
            "Downloading:  12% 78.7M/681M [00:01<00:09, 60.6MB/s]\u001b[A\n",
            "Downloading:  12% 84.7M/681M [00:01<00:09, 60.1MB/s]\u001b[A\n",
            "Downloading:  13% 90.7M/681M [00:01<00:10, 55.1MB/s]\u001b[A\n",
            "Downloading:  14% 96.5M/681M [00:01<00:10, 55.9MB/s]\u001b[A\n",
            "Downloading:  15% 102M/681M [00:01<00:10, 55.1MB/s] \u001b[A\n",
            "Downloading:  16% 108M/681M [00:01<00:10, 54.3MB/s]\u001b[A\n",
            "Downloading:  17% 114M/681M [00:01<00:10, 55.3MB/s]\u001b[A\n",
            "Downloading:  18% 119M/681M [00:02<00:10, 56.0MB/s]\u001b[A\n",
            "Downloading:  18% 125M/681M [00:02<00:09, 55.8MB/s]\u001b[A\n",
            "Downloading:  19% 130M/681M [00:02<00:09, 55.7MB/s]\u001b[A\n",
            "Downloading:  20% 136M/681M [00:02<00:09, 55.4MB/s]\u001b[A\n",
            "Downloading:  21% 142M/681M [00:02<00:09, 55.5MB/s]\u001b[A\n",
            "Downloading:  22% 147M/681M [00:02<00:09, 54.8MB/s]\u001b[A\n",
            "Downloading:  22% 153M/681M [00:02<00:09, 53.3MB/s]\u001b[A\n",
            "Downloading:  23% 158M/681M [00:02<00:09, 53.8MB/s]\u001b[A\n",
            "Downloading:  24% 164M/681M [00:02<00:09, 53.8MB/s]\u001b[A\n",
            "Downloading:  25% 169M/681M [00:02<00:09, 54.1MB/s]\u001b[A\n",
            "Downloading:  26% 175M/681M [00:03<00:09, 54.7MB/s]\u001b[A\n",
            "Downloading:  26% 180M/681M [00:03<00:10, 48.9MB/s]\u001b[A\n",
            "Downloading:  27% 186M/681M [00:03<00:09, 50.2MB/s]\u001b[A\n",
            "Downloading:  28% 191M/681M [00:03<00:09, 51.7MB/s]\u001b[A\n",
            "Downloading:  29% 197M/681M [00:03<00:09, 52.6MB/s]\u001b[A\n",
            "Downloading:  30% 202M/681M [00:03<00:08, 54.0MB/s]\u001b[A\n",
            "Downloading:  31% 208M/681M [00:03<00:08, 55.0MB/s]\u001b[A\n",
            "Downloading:  31% 214M/681M [00:03<00:09, 51.4MB/s]\u001b[A\n",
            "Downloading:  32% 219M/681M [00:03<00:08, 53.4MB/s]\u001b[A\n",
            "Downloading:  34% 229M/681M [00:04<00:06, 66.7MB/s]\u001b[A\n",
            "Downloading:  35% 239M/681M [00:04<00:05, 75.1MB/s]\u001b[A\n",
            "Downloading:  36% 247M/681M [00:04<00:05, 76.3MB/s]\u001b[A\n",
            "Downloading:  38% 256M/681M [00:04<00:05, 81.6MB/s]\u001b[A\n",
            "Downloading:  39% 267M/681M [00:04<00:04, 87.7MB/s]\u001b[A\n",
            "Downloading:  41% 277M/681M [00:04<00:04, 91.7MB/s]\u001b[A\n",
            "Downloading:  42% 286M/681M [00:04<00:04, 87.2MB/s]\u001b[A\n",
            "Downloading:  43% 296M/681M [00:04<00:04, 90.4MB/s]\u001b[A\n",
            "Downloading:  45% 305M/681M [00:04<00:04, 89.1MB/s]\u001b[A\n",
            "Downloading:  46% 314M/681M [00:04<00:04, 82.3MB/s]\u001b[A\n",
            "Downloading:  47% 323M/681M [00:05<00:04, 86.1MB/s]\u001b[A\n",
            "Downloading:  49% 332M/681M [00:05<00:04, 86.5MB/s]\u001b[A\n",
            "Downloading:  50% 341M/681M [00:05<00:04, 85.0MB/s]\u001b[A\n",
            "Downloading:  51% 349M/681M [00:05<00:04, 81.9MB/s]\u001b[A\n",
            "Downloading:  53% 359M/681M [00:05<00:03, 85.8MB/s]\u001b[A\n",
            "Downloading:  54% 368M/681M [00:05<00:03, 88.2MB/s]\u001b[A\n",
            "Downloading:  55% 378M/681M [00:05<00:03, 89.3MB/s]\u001b[A\n",
            "Downloading:  57% 387M/681M [00:05<00:03, 87.2MB/s]\u001b[A\n",
            "Downloading:  58% 396M/681M [00:05<00:03, 88.3MB/s]\u001b[A\n",
            "Downloading:  59% 405M/681M [00:06<00:03, 89.3MB/s]\u001b[A\n",
            "Downloading:  61% 414M/681M [00:06<00:03, 86.8MB/s]\u001b[A\n",
            "Downloading:  62% 422M/681M [00:06<00:03, 83.3MB/s]\u001b[A\n",
            "Downloading:  63% 431M/681M [00:06<00:02, 84.5MB/s]\u001b[A\n",
            "Downloading:  65% 440M/681M [00:06<00:02, 85.9MB/s]\u001b[A\n",
            "Downloading:  66% 450M/681M [00:06<00:02, 88.6MB/s]\u001b[A\n",
            "Downloading:  68% 460M/681M [00:06<00:02, 92.6MB/s]\u001b[A\n",
            "Downloading:  69% 470M/681M [00:06<00:02, 95.9MB/s]\u001b[A\n",
            "Downloading:  70% 480M/681M [00:06<00:02, 85.5MB/s]\u001b[A\n",
            "Downloading:  72% 489M/681M [00:07<00:02, 76.6MB/s]\u001b[A\n",
            "Downloading:  73% 498M/681M [00:07<00:02, 81.9MB/s]\u001b[A\n",
            "Downloading:  75% 508M/681M [00:07<00:02, 86.0MB/s]\u001b[A\n",
            "Downloading:  76% 518M/681M [00:07<00:01, 89.5MB/s]\u001b[A\n",
            "Downloading:  78% 528M/681M [00:07<00:01, 92.0MB/s]\u001b[A\n",
            "Downloading:  79% 537M/681M [00:07<00:01, 93.4MB/s]\u001b[A\n",
            "Downloading:  80% 547M/681M [00:07<00:01, 91.4MB/s]\u001b[A\n",
            "Downloading:  82% 556M/681M [00:07<00:01, 87.8MB/s]\u001b[A\n",
            "Downloading:  83% 565M/681M [00:07<00:01, 89.2MB/s]\u001b[A\n",
            "Downloading:  84% 575M/681M [00:07<00:01, 91.5MB/s]\u001b[A\n",
            "Downloading:  86% 584M/681M [00:08<00:01, 90.6MB/s]\u001b[A\n",
            "Downloading:  87% 593M/681M [00:08<00:01, 86.1MB/s]\u001b[A\n",
            "Downloading:  89% 603M/681M [00:08<00:00, 87.8MB/s]\u001b[A\n",
            "Downloading:  90% 611M/681M [00:08<00:00, 88.0MB/s]\u001b[A\n",
            "Downloading:  91% 620M/681M [00:08<00:00, 85.7MB/s]\u001b[A\n",
            "Downloading:  92% 629M/681M [00:08<00:00, 83.5MB/s]\u001b[A\n",
            "Downloading:  94% 639M/681M [00:08<00:00, 87.7MB/s]\u001b[A\n",
            "Downloading:  95% 648M/681M [00:08<00:00, 88.5MB/s]\u001b[A\n",
            "Downloading:  96% 657M/681M [00:08<00:00, 85.2MB/s]\u001b[A\n",
            "Downloading:  98% 667M/681M [00:09<00:00, 89.5MB/s]\u001b[A\n",
            "Downloading: 100% 681M/681M [00:09<00:00, 74.2MB/s]\n",
            "Fetching 12 files:  50% 6/12 [00:11<00:11,  1.87s/it]\n",
            "Downloading: 100% 815/815 [00:00<00:00, 659kB/s]\n",
            "Fetching 12 files:  67% 8/12 [00:12<00:04,  1.14s/it]\n",
            "Downloading: 100% 900/900 [00:00<00:00, 807kB/s]\n",
            "Fetching 12 files:  75% 9/12 [00:13<00:03,  1.01s/it]\n",
            "Downloading:   0% 0.00/1.73G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   0% 4.64M/1.73G [00:00<00:37, 46.4MB/s]\u001b[A\n",
            "Downloading:   1% 9.51M/1.73G [00:00<00:36, 47.7MB/s]\u001b[A\n",
            "Downloading:   1% 17.3M/1.73G [00:00<00:27, 61.5MB/s]\u001b[A\n",
            "Downloading:   1% 25.6M/1.73G [00:00<00:24, 69.9MB/s]\u001b[A\n",
            "Downloading:   2% 34.5M/1.73G [00:00<00:22, 77.0MB/s]\u001b[A\n",
            "Downloading:   2% 42.6M/1.73G [00:00<00:21, 78.4MB/s]\u001b[A\n",
            "Downloading:   3% 50.5M/1.73G [00:00<00:22, 76.3MB/s]\u001b[A\n",
            "Downloading:   3% 59.1M/1.73G [00:00<00:21, 79.5MB/s]\u001b[A\n",
            "Downloading:   4% 68.5M/1.73G [00:00<00:19, 84.0MB/s]\u001b[A\n",
            "Downloading:   4% 77.0M/1.73G [00:01<00:19, 84.2MB/s]\u001b[A\n",
            "Downloading:   5% 87.0M/1.73G [00:01<00:18, 89.1MB/s]\u001b[A\n",
            "Downloading:   6% 96.1M/1.73G [00:01<00:18, 89.6MB/s]\u001b[A\n",
            "Downloading:   6% 105M/1.73G [00:01<00:18, 89.9MB/s] \u001b[A\n",
            "Downloading:   7% 114M/1.73G [00:01<00:21, 76.1MB/s]\u001b[A\n",
            "Downloading:   7% 123M/1.73G [00:01<00:20, 79.8MB/s]\u001b[A\n",
            "Downloading:   8% 133M/1.73G [00:01<00:19, 83.6MB/s]\u001b[A\n",
            "Downloading:   8% 142M/1.73G [00:01<00:18, 87.6MB/s]\u001b[A\n",
            "Downloading:   9% 153M/1.73G [00:01<00:17, 92.1MB/s]\u001b[A\n",
            "Downloading:   9% 162M/1.73G [00:01<00:16, 93.0MB/s]\u001b[A\n",
            "Downloading:  10% 172M/1.73G [00:02<00:17, 91.6MB/s]\u001b[A\n",
            "Downloading:  10% 181M/1.73G [00:02<00:17, 88.6MB/s]\u001b[A\n",
            "Downloading:  11% 190M/1.73G [00:02<00:18, 81.3MB/s]\u001b[A\n",
            "Downloading:  11% 199M/1.73G [00:02<00:18, 83.9MB/s]\u001b[A\n",
            "Downloading:  12% 207M/1.73G [00:02<00:18, 82.5MB/s]\u001b[A\n",
            "Downloading:  12% 216M/1.73G [00:02<00:18, 82.5MB/s]\u001b[A\n",
            "Downloading:  13% 224M/1.73G [00:02<00:18, 80.4MB/s]\u001b[A\n",
            "Downloading:  13% 232M/1.73G [00:02<00:19, 75.3MB/s]\u001b[A\n",
            "Downloading:  14% 240M/1.73G [00:02<00:19, 77.5MB/s]\u001b[A\n",
            "Downloading:  14% 248M/1.73G [00:03<01:03, 23.4MB/s]\u001b[A\n",
            "Downloading:  15% 254M/1.73G [00:04<00:56, 26.3MB/s]\u001b[A\n",
            "Downloading:  15% 262M/1.73G [00:04<00:44, 32.8MB/s]\u001b[A\n",
            "Downloading:  16% 270M/1.73G [00:04<00:35, 41.4MB/s]\u001b[A\n",
            "Downloading:  16% 280M/1.73G [00:04<00:28, 51.1MB/s]\u001b[A\n",
            "Downloading:  17% 289M/1.73G [00:04<00:24, 58.8MB/s]\u001b[A\n",
            "Downloading:  17% 297M/1.73G [00:04<00:22, 64.5MB/s]\u001b[A\n",
            "Downloading:  18% 306M/1.73G [00:04<00:20, 70.2MB/s]\u001b[A\n",
            "Downloading:  18% 315M/1.73G [00:04<00:18, 76.1MB/s]\u001b[A\n",
            "Downloading:  19% 324M/1.73G [00:04<00:17, 78.9MB/s]\u001b[A\n",
            "Downloading:  19% 333M/1.73G [00:04<00:16, 84.2MB/s]\u001b[A\n",
            "Downloading:  20% 343M/1.73G [00:05<00:16, 86.3MB/s]\u001b[A\n",
            "Downloading:  20% 352M/1.73G [00:05<00:15, 86.3MB/s]\u001b[A\n",
            "Downloading:  21% 361M/1.73G [00:05<00:15, 87.1MB/s]\u001b[A\n",
            "Downloading:  21% 369M/1.73G [00:05<00:17, 78.8MB/s]\u001b[A\n",
            "Downloading:  22% 380M/1.73G [00:05<00:15, 84.9MB/s]\u001b[A\n",
            "Downloading:  22% 389M/1.73G [00:05<00:15, 88.5MB/s]\u001b[A\n",
            "Downloading:  23% 398M/1.73G [00:05<00:15, 85.5MB/s]\u001b[A\n",
            "Downloading:  24% 408M/1.73G [00:05<00:14, 89.2MB/s]\u001b[A\n",
            "Downloading:  24% 418M/1.73G [00:05<00:14, 92.0MB/s]\u001b[A\n",
            "Downloading:  25% 427M/1.73G [00:05<00:15, 85.3MB/s]\u001b[A\n",
            "Downloading:  25% 436M/1.73G [00:06<00:16, 78.9MB/s]\u001b[A\n",
            "Downloading:  26% 445M/1.73G [00:06<00:15, 81.2MB/s]\u001b[A\n",
            "Downloading:  26% 455M/1.73G [00:06<00:14, 85.3MB/s]\u001b[A\n",
            "Downloading:  27% 464M/1.73G [00:06<00:14, 89.4MB/s]\u001b[A\n",
            "Downloading:  27% 474M/1.73G [00:06<00:13, 92.0MB/s]\u001b[A\n",
            "Downloading:  28% 484M/1.73G [00:06<00:13, 92.9MB/s]\u001b[A\n",
            "Downloading:  28% 493M/1.73G [00:06<00:13, 91.7MB/s]\u001b[A\n",
            "Downloading:  29% 502M/1.73G [00:06<00:13, 88.7MB/s]\u001b[A\n",
            "Downloading:  30% 511M/1.73G [00:06<00:15, 81.1MB/s]\u001b[A\n",
            "Downloading:  30% 520M/1.73G [00:07<00:14, 83.7MB/s]\u001b[A\n",
            "Downloading:  31% 529M/1.73G [00:07<00:14, 81.7MB/s]\u001b[A\n",
            "Downloading:  31% 537M/1.73G [00:07<00:14, 82.0MB/s]\u001b[A\n",
            "Downloading:  31% 545M/1.73G [00:07<00:15, 75.0MB/s]\u001b[A\n",
            "Downloading:  32% 555M/1.73G [00:07<00:14, 80.5MB/s]\u001b[A\n",
            "Downloading:  33% 565M/1.73G [00:07<00:13, 86.4MB/s]\u001b[A\n",
            "Downloading:  33% 574M/1.73G [00:07<00:13, 83.5MB/s]\u001b[A\n",
            "Downloading:  34% 583M/1.73G [00:07<00:13, 85.1MB/s]\u001b[A\n",
            "Downloading:  34% 592M/1.73G [00:07<00:12, 88.2MB/s]\u001b[A\n",
            "Downloading:  35% 601M/1.73G [00:08<00:12, 88.8MB/s]\u001b[A\n",
            "Downloading:  35% 610M/1.73G [00:08<00:14, 75.3MB/s]\u001b[A\n",
            "Downloading:  36% 620M/1.73G [00:08<00:13, 81.3MB/s]\u001b[A\n",
            "Downloading:  36% 630M/1.73G [00:08<00:12, 85.4MB/s]\u001b[A\n",
            "Downloading:  37% 639M/1.73G [00:08<00:12, 88.0MB/s]\u001b[A\n",
            "Downloading:  37% 649M/1.73G [00:08<00:11, 90.3MB/s]\u001b[A\n",
            "Downloading:  38% 658M/1.73G [00:08<00:12, 88.5MB/s]\u001b[A\n",
            "Downloading:  39% 667M/1.73G [00:08<00:12, 87.2MB/s]\u001b[A\n",
            "Downloading:  39% 676M/1.73G [00:08<00:11, 88.1MB/s]\u001b[A\n",
            "Downloading:  40% 685M/1.73G [00:09<00:11, 88.2MB/s]\u001b[A\n",
            "Downloading:  40% 694M/1.73G [00:09<00:11, 88.3MB/s]\u001b[A\n",
            "Downloading:  41% 703M/1.73G [00:09<00:11, 86.2MB/s]\u001b[A\n",
            "Downloading:  41% 712M/1.73G [00:09<00:11, 87.8MB/s]\u001b[A\n",
            "Downloading:  42% 721M/1.73G [00:09<00:12, 80.0MB/s]\u001b[A\n",
            "Downloading:  42% 730M/1.73G [00:09<00:12, 83.1MB/s]\u001b[A\n",
            "Downloading:  43% 738M/1.73G [00:09<00:12, 82.0MB/s]\u001b[A\n",
            "Downloading:  43% 747M/1.73G [00:09<00:11, 84.6MB/s]\u001b[A\n",
            "Downloading:  44% 757M/1.73G [00:09<00:11, 87.1MB/s]\u001b[A\n",
            "Downloading:  44% 766M/1.73G [00:09<00:11, 87.0MB/s]\u001b[A\n",
            "Downloading:  45% 774M/1.73G [00:10<00:10, 87.6MB/s]\u001b[A\n",
            "Downloading:  45% 784M/1.73G [00:10<00:10, 88.7MB/s]\u001b[A\n",
            "Downloading:  46% 792M/1.73G [00:10<00:10, 86.8MB/s]\u001b[A\n",
            "Downloading:  46% 801M/1.73G [00:10<00:11, 79.4MB/s]\u001b[A\n",
            "Downloading:  47% 811M/1.73G [00:10<00:11, 83.2MB/s]\u001b[A\n",
            "Downloading:  47% 819M/1.73G [00:10<00:11, 82.7MB/s]\u001b[A\n",
            "Downloading:  48% 827M/1.73G [00:10<00:10, 82.5MB/s]\u001b[A\n",
            "Downloading:  48% 836M/1.73G [00:10<00:11, 78.0MB/s]\u001b[A\n",
            "Downloading:  49% 845M/1.73G [00:10<00:10, 81.6MB/s]\u001b[A\n",
            "Downloading:  49% 853M/1.73G [00:11<00:10, 81.7MB/s]\u001b[A\n",
            "Downloading:  50% 862M/1.73G [00:11<00:10, 83.9MB/s]\u001b[A\n",
            "Downloading:  50% 870M/1.73G [00:11<00:10, 81.7MB/s]\u001b[A\n",
            "Downloading:  51% 879M/1.73G [00:11<00:10, 83.1MB/s]\u001b[A\n",
            "Downloading:  51% 888M/1.73G [00:11<00:10, 84.1MB/s]\u001b[A\n",
            "Downloading:  52% 897M/1.73G [00:11<00:09, 85.8MB/s]\u001b[A\n",
            "Downloading:  52% 905M/1.73G [00:11<00:09, 86.3MB/s]\u001b[A\n",
            "Downloading:  53% 914M/1.73G [00:11<00:09, 87.2MB/s]\u001b[A\n",
            "Downloading:  53% 923M/1.73G [00:11<00:11, 71.5MB/s]\u001b[A\n",
            "Downloading:  54% 932M/1.73G [00:12<00:10, 76.8MB/s]\u001b[A\n",
            "Downloading:  54% 941M/1.73G [00:12<00:09, 80.8MB/s]\u001b[A\n",
            "Downloading:  55% 950M/1.73G [00:12<00:09, 82.0MB/s]\u001b[A\n",
            "Downloading:  55% 958M/1.73G [00:12<00:09, 81.9MB/s]\u001b[A\n",
            "Downloading:  56% 967M/1.73G [00:12<00:09, 83.3MB/s]\u001b[A\n",
            "Downloading:  56% 976M/1.73G [00:12<00:08, 84.1MB/s]\u001b[A\n",
            "Downloading:  57% 985M/1.73G [00:12<00:08, 86.9MB/s]\u001b[A\n",
            "Downloading:  57% 994M/1.73G [00:12<00:08, 89.2MB/s]\u001b[A\n",
            "Downloading:  58% 1.00G/1.73G [00:12<00:08, 90.2MB/s]\u001b[A\n",
            "Downloading:  58% 1.01G/1.73G [00:12<00:07, 90.6MB/s]\u001b[A\n",
            "Downloading:  59% 1.02G/1.73G [00:13<00:08, 84.1MB/s]\u001b[A\n",
            "Downloading:  59% 1.03G/1.73G [00:13<00:09, 74.8MB/s]\u001b[A\n",
            "Downloading:  60% 1.04G/1.73G [00:13<00:08, 77.9MB/s]\u001b[A\n",
            "Downloading:  61% 1.05G/1.73G [00:13<00:08, 81.7MB/s]\u001b[A\n",
            "Downloading:  61% 1.06G/1.73G [00:13<00:08, 82.3MB/s]\u001b[A\n",
            "Downloading:  61% 1.07G/1.73G [00:13<00:08, 78.9MB/s]\u001b[A\n",
            "Downloading:  62% 1.07G/1.73G [00:13<00:08, 81.5MB/s]\u001b[A\n",
            "Downloading:  63% 1.08G/1.73G [00:13<00:07, 86.0MB/s]\u001b[A\n",
            "Downloading:  63% 1.09G/1.73G [00:13<00:07, 88.1MB/s]\u001b[A\n",
            "Downloading:  64% 1.10G/1.73G [00:14<00:07, 82.2MB/s]\u001b[A\n",
            "Downloading:  64% 1.11G/1.73G [00:14<00:07, 85.5MB/s]\u001b[A\n",
            "Downloading:  65% 1.12G/1.73G [00:14<00:06, 88.0MB/s]\u001b[A\n",
            "Downloading:  65% 1.13G/1.73G [00:14<00:07, 85.0MB/s]\u001b[A\n",
            "Downloading:  66% 1.14G/1.73G [00:14<00:06, 87.2MB/s]\u001b[A\n",
            "Downloading:  66% 1.15G/1.73G [00:14<00:06, 89.0MB/s]\u001b[A\n",
            "Downloading:  67% 1.16G/1.73G [00:14<00:06, 89.8MB/s]\u001b[A\n",
            "Downloading:  67% 1.17G/1.73G [00:14<00:08, 70.3MB/s]\u001b[A\n",
            "Downloading:  68% 1.18G/1.73G [00:14<00:07, 74.7MB/s]\u001b[A\n",
            "Downloading:  68% 1.18G/1.73G [00:15<00:06, 80.3MB/s]\u001b[A\n",
            "Downloading:  69% 1.19G/1.73G [00:15<00:06, 84.1MB/s]\u001b[A\n",
            "Downloading:  70% 1.20G/1.73G [00:15<00:05, 88.6MB/s]\u001b[A\n",
            "Downloading:  70% 1.21G/1.73G [00:15<00:05, 87.0MB/s]\u001b[A\n",
            "Downloading:  71% 1.22G/1.73G [00:15<00:05, 89.2MB/s]\u001b[A\n",
            "Downloading:  71% 1.23G/1.73G [00:15<00:05, 86.2MB/s]\u001b[A\n",
            "Downloading:  72% 1.24G/1.73G [00:15<00:05, 87.7MB/s]\u001b[A\n",
            "Downloading:  72% 1.25G/1.73G [00:15<00:05, 89.9MB/s]\u001b[A\n",
            "Downloading:  73% 1.26G/1.73G [00:15<00:05, 90.1MB/s]\u001b[A\n",
            "Downloading:  73% 1.27G/1.73G [00:15<00:05, 85.2MB/s]\u001b[A\n",
            "Downloading:  74% 1.28G/1.73G [00:16<00:05, 86.5MB/s]\u001b[A\n",
            "Downloading:  74% 1.29G/1.73G [00:16<00:04, 90.1MB/s]\u001b[A\n",
            "Downloading:  75% 1.30G/1.73G [00:16<00:04, 90.6MB/s]\u001b[A\n",
            "Downloading:  75% 1.31G/1.73G [00:16<00:05, 82.5MB/s]\u001b[A\n",
            "Downloading:  76% 1.31G/1.73G [00:16<00:04, 84.0MB/s]\u001b[A\n",
            "Downloading:  76% 1.32G/1.73G [00:16<00:07, 57.2MB/s]\u001b[A\n",
            "Downloading:  77% 1.33G/1.73G [00:16<00:06, 62.2MB/s]\u001b[A\n",
            "Downloading:  77% 1.34G/1.73G [00:16<00:06, 64.6MB/s]\u001b[A\n",
            "Downloading:  78% 1.35G/1.73G [00:17<00:05, 69.7MB/s]\u001b[A\n",
            "Downloading:  78% 1.36G/1.73G [00:17<00:04, 75.8MB/s]\u001b[A\n",
            "Downloading:  79% 1.37G/1.73G [00:17<00:04, 81.3MB/s]\u001b[A\n",
            "Downloading:  79% 1.37G/1.73G [00:17<00:04, 82.0MB/s]\u001b[A\n",
            "Downloading:  80% 1.38G/1.73G [00:17<00:04, 86.1MB/s]\u001b[A\n",
            "Downloading:  80% 1.39G/1.73G [00:17<00:03, 87.7MB/s]\u001b[A\n",
            "Downloading:  81% 1.40G/1.73G [00:17<00:03, 86.8MB/s]\u001b[A\n",
            "Downloading:  81% 1.41G/1.73G [00:17<00:03, 88.5MB/s]\u001b[A\n",
            "Downloading:  82% 1.42G/1.73G [00:17<00:03, 90.2MB/s]\u001b[A\n",
            "Downloading:  83% 1.43G/1.73G [00:17<00:03, 89.8MB/s]\u001b[A\n",
            "Downloading:  83% 1.44G/1.73G [00:18<00:03, 90.1MB/s]\u001b[A\n",
            "Downloading:  84% 1.45G/1.73G [00:18<00:03, 79.7MB/s]\u001b[A\n",
            "Downloading:  84% 1.46G/1.73G [00:18<00:03, 81.7MB/s]\u001b[A\n",
            "Downloading:  85% 1.47G/1.73G [00:18<00:03, 84.4MB/s]\u001b[A\n",
            "Downloading:  85% 1.48G/1.73G [00:18<00:02, 87.0MB/s]\u001b[A\n",
            "Downloading:  86% 1.48G/1.73G [00:18<00:02, 83.2MB/s]\u001b[A\n",
            "Downloading:  86% 1.49G/1.73G [00:18<00:02, 85.4MB/s]\u001b[A\n",
            "Downloading:  87% 1.50G/1.73G [00:18<00:02, 88.1MB/s]\u001b[A\n",
            "Downloading:  87% 1.51G/1.73G [00:18<00:02, 81.0MB/s]\u001b[A\n",
            "Downloading:  88% 1.52G/1.73G [00:19<00:02, 84.3MB/s]\u001b[A\n",
            "Downloading:  88% 1.53G/1.73G [00:19<00:02, 87.6MB/s]\u001b[A\n",
            "Downloading:  89% 1.54G/1.73G [00:19<00:02, 87.4MB/s]\u001b[A\n",
            "Downloading:  89% 1.55G/1.73G [00:19<00:02, 89.5MB/s]\u001b[A\n",
            "Downloading:  90% 1.56G/1.73G [00:19<00:01, 89.1MB/s]\u001b[A\n",
            "Downloading:  91% 1.57G/1.73G [00:19<00:01, 91.5MB/s]\u001b[A\n",
            "Downloading:  91% 1.58G/1.73G [00:19<00:01, 81.7MB/s]\u001b[A\n",
            "Downloading:  92% 1.59G/1.73G [00:19<00:01, 76.9MB/s]\u001b[A\n",
            "Downloading:  92% 1.59G/1.73G [00:19<00:01, 81.6MB/s]\u001b[A\n",
            "Downloading:  93% 1.60G/1.73G [00:20<00:01, 84.7MB/s]\u001b[A\n",
            "Downloading:  93% 1.61G/1.73G [00:20<00:01, 88.5MB/s]\u001b[A\n",
            "Downloading:  94% 1.62G/1.73G [00:20<00:01, 90.7MB/s]\u001b[A\n",
            "Downloading:  94% 1.63G/1.73G [00:20<00:01, 91.5MB/s]\u001b[A\n",
            "Downloading:  95% 1.64G/1.73G [00:20<00:00, 90.8MB/s]\u001b[A\n",
            "Downloading:  95% 1.65G/1.73G [00:20<00:00, 85.0MB/s]\u001b[A\n",
            "Downloading:  96% 1.66G/1.73G [00:20<00:00, 87.4MB/s]\u001b[A\n",
            "Downloading:  96% 1.67G/1.73G [00:21<00:02, 22.2MB/s]\u001b[A\n",
            "Downloading:  97% 1.68G/1.73G [00:21<00:02, 26.6MB/s]\u001b[A\n",
            "Downloading:  97% 1.68G/1.73G [00:22<00:01, 30.8MB/s]\u001b[A\n",
            "Downloading:  98% 1.69G/1.73G [00:22<00:01, 38.8MB/s]\u001b[A\n",
            "Downloading:  98% 1.70G/1.73G [00:22<00:00, 48.0MB/s]\u001b[A\n",
            "Downloading:  99% 1.71G/1.73G [00:22<00:00, 57.0MB/s]\u001b[A\n",
            "Downloading:  99% 1.72G/1.73G [00:22<00:00, 64.5MB/s]\u001b[A\n",
            "Downloading: 100% 1.73G/1.73G [00:22<00:00, 76.7MB/s]\n",
            "Fetching 12 files:  83% 10/12 [00:36<00:15,  7.75s/it]\n",
            "Downloading: 100% 602/602 [00:00<00:00, 511kB/s]\n",
            "Fetching 12 files:  92% 11/12 [00:36<00:05,  5.61s/it]\n",
            "Downloading:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   4% 7.16M/167M [00:00<00:02, 71.6MB/s]\u001b[A\n",
            "Downloading:  10% 16.3M/167M [00:00<00:01, 83.1MB/s]\u001b[A\n",
            "Downloading:  15% 25.4M/167M [00:00<00:01, 86.6MB/s]\u001b[A\n",
            "Downloading:  21% 35.2M/167M [00:00<00:01, 91.5MB/s]\u001b[A\n",
            "Downloading:  27% 45.0M/167M [00:00<00:01, 93.8MB/s]\u001b[A\n",
            "Downloading:  33% 54.4M/167M [00:00<00:01, 84.9MB/s]\u001b[A\n",
            "Downloading:  38% 63.0M/167M [00:01<00:05, 19.7MB/s]\u001b[A\n",
            "Downloading:  43% 72.5M/167M [00:01<00:03, 26.6MB/s]\u001b[A\n",
            "Downloading:  49% 82.9M/167M [00:02<00:02, 35.6MB/s]\u001b[A\n",
            "Downloading:  54% 91.0M/167M [00:03<00:04, 16.7MB/s]\u001b[A\n",
            "Downloading:  58% 97.5M/167M [00:03<00:03, 20.3MB/s]\u001b[A\n",
            "Downloading:  64% 108M/167M [00:03<00:02, 28.0MB/s] \u001b[A\n",
            "Downloading:  69% 115M/167M [00:04<00:03, 14.6MB/s]\u001b[A\n",
            "Downloading:  75% 125M/167M [00:04<00:02, 20.6MB/s]\u001b[A\n",
            "Downloading:  78% 131M/167M [00:05<00:02, 12.7MB/s]\u001b[A\n",
            "Downloading:  83% 140M/167M [00:05<00:01, 17.0MB/s]\u001b[A\n",
            "Downloading:  89% 149M/167M [00:06<00:00, 23.4MB/s]\u001b[A\n",
            "Downloading: 100% 167M/167M [00:06<00:00, 27.0MB/s]\n",
            "Fetching 12 files: 100% 12/12 [00:43<00:00,  3.62s/it]\n",
            "Model set-up\n",
            "WAITING\n",
            "cuda\n",
            "WAITING\n",
            "cuda\n",
            "cuda\n",
            "WAITING\n",
            "DONE\n",
            "100% 36/36 [00:05<00:00,  6.46it/s]\n",
            "100% 36/36 [00:05<00:00,  6.38it/s]\n",
            "cuda\n",
            "cuda\n",
            "WAITING\n",
            "DONE\n",
            "100% 36/36 [00:05<00:00,  6.50it/s]\n",
            "100% 36/36 [00:05<00:00,  6.35it/s]\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}